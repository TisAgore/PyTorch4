{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FOnJIT1cG2Fm"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models\n",
        "class BasicResidualBlock(nn.Module):\n",
        "    \"\"\"Базовый Residual блок: 2 conv слоя.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.functional.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return nn.functional.relu(out)\n",
        "\n",
        "class BottleneckResidualBlock(nn.Module):\n",
        "    \"\"\"Bottleneck Residual блок: 1x1 -> 3x3 -> 1x1.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1, bottleneck_ratio=4):\n",
        "        super().__init__()\n",
        "        bottleneck_channels = out_channels // bottleneck_ratio\n",
        "        self.conv1 = nn.Conv2d(in_channels, bottleneck_channels, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
        "        self.conv2 = nn.Conv2d(bottleneck_channels, bottleneck_channels, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
        "        self.conv3 = nn.Conv2d(bottleneck_channels, out_channels, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.functional.relu(self.bn1(self.conv1(x)))\n",
        "        out = nn.functional.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        return nn.functional.relu(out)\n",
        "\n",
        "class WideResidualBlock(nn.Module):\n",
        "    \"\"\"Wide Residual блок: увеличенное число каналов.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1, widen_factor=3):\n",
        "        super().__init__()\n",
        "        mid_channels = out_channels * widen_factor\n",
        "        self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv2 = nn.Conv2d(mid_channels, out_channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.functional.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return nn.functional.relu(out)\n",
        "\n",
        "class BasicResNet(nn.Module):\n",
        "    \"\"\"ResNet с базовыми блоками.\"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.layer1 = BasicResidualBlock(16, 32, stride=2)\n",
        "        self.layer2 = BasicResidualBlock(32, 64, stride=2)\n",
        "        self.layer3 = BasicResidualBlock(64, 128, stride=2)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv(x))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class BottleneckResNet(nn.Module):\n",
        "    \"\"\"ResNet с bottleneck блоками.\"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.layer1 = BottleneckResidualBlock(16, 32, stride=2)\n",
        "        self.layer2 = BottleneckResidualBlock(32, 64, stride=2)\n",
        "        self.layer3 = BottleneckResidualBlock(64, 128, stride=2)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv(x))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    \"\"\"ResNet с wide residual блоками.\"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.layer1 = WideResidualBlock(16, 32, stride=2, widen_factor=3)\n",
        "        self.layer2 = WideResidualBlock(32, 64, stride=2, widen_factor=3)\n",
        "        self.layer3 = WideResidualBlock(64, 128, stride=2, widen_factor=3)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv(x))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "Ggr4iyA5KVkU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "def get_data_loaders(dataset_name, batch_size=128):\n",
        "    \"\"\"Загружает и возвращает загрузчики данных для указанного датасета.\"\"\"\n",
        "    if dataset_name == 'MNIST':\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        train = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "        test = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "        class_names = [str(i) for i in range(10)]\n",
        "        return train_loader, test_loader, class_names\n",
        "    elif dataset_name == 'CIFAR10':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "        ])\n",
        "        train = datasets.CIFAR10('data', train=True, download=True, transform=transform_train)\n",
        "        test = datasets.CIFAR10('data', train=False, download=True, transform=transform_test)\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "        class_names = train.classes\n",
        "        return train_loader, test_loader, class_names\n",
        "    else:\n",
        "        raise ValueError(f\"Неизвестный датасет: {dataset_name}\")\n",
        "\n",
        "def plot_grad_flow(named_parameters, save_path):\n",
        "    \"\"\"Визуализирует средние значения градиентов по слоям.\"\"\"\n",
        "    ave_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if p.requires_grad and p.grad is not None and \"bias\" not in n:\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean().item())\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(ave_grads, alpha=0.7, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\", fontsize=8)\n",
        "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
        "    plt.xlabel(\"Слои\")\n",
        "    plt.ylabel(\"Средний градиент\")\n",
        "    plt.title(\"Градиентный поток\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def train(model, train_loader, test_loader, epochs=20, log_prefix=\"\", grad_flow_plot=False, grad_flow_path=None):\n",
        "    device = next(model.parameters()).device\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = torch.nn.functional.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            if grad_flow_plot and grad_flow_path and epoch % 5 == 0:\n",
        "                plot_grad_flow(model.named_parameters(), grad_flow_path.replace('.png', f'_epoch{epoch}.png'))\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "        test_loss, test_acc = test(model, test_loader)\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(test_acc)\n",
        "    return history\n",
        "\n",
        "def test(model, test_loader):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss += torch.nn.functional.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "    loss /= len(test_loader.dataset)\n",
        "    acc = correct / len(test_loader.dataset)\n",
        "    return loss, acc\n",
        "\n",
        "def compare_models(histories, labels, save_path):\n",
        "    \"\"\"Сохраняет сравнение историй обучения разных моделей в файл.\"\"\"\n",
        "    results = {}\n",
        "    for label, history in zip(labels, histories):\n",
        "        results[label] = {\n",
        "            'train_loss': history['train_loss'],\n",
        "            'test_loss': history['test_loss'],\n",
        "            'test_acc': history['test_acc'],\n",
        "        }\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Возвращает количество обучаемых параметров модели.\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def plot_metrics(histories, labels, save_dir):\n",
        "    \"\"\"Строит и сохраняет графики метрик обучения для нескольких моделей.\"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    metrics = ['train_loss', 'train_acc', 'test_loss', 'test_acc']\n",
        "    for metric in metrics:\n",
        "        plt.figure()\n",
        "        for history, label in zip(histories, labels):\n",
        "            plt.plot(history[metric], label=label)\n",
        "        plt.title(metric)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric)\n",
        "        plt.legend()\n",
        "        plt.savefig(os.path.join(save_dir, f\"{metric}.png\"))\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "HXxbHu20Lv1E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3: Кастомные слои и эксперименты"
      ],
      "metadata": {
        "id": "WXsLNu39MMvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader, _ = get_data_loaders('CIFAR10', batch_size=128)\n",
        "\n",
        "models = [\n",
        "    (\"BasicResNet\", BasicResNet().to(device)),\n",
        "    (\"BottleneckResNet\", BottleneckResNet().to(device)),\n",
        "    (\"WideResNet\", WideResNet().to(device)),\n",
        "]\n",
        "\n",
        "histories = []\n",
        "param_counts = []\n",
        "train_times = []\n",
        "test_accs = []\n",
        "\n",
        "for name, model in models:\n",
        "    params = count_parameters(model)\n",
        "    param_counts.append((name, params))\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = train(model, train_loader, test_loader, epochs=20, log_prefix=name)\n",
        "    train_duration = time.time() - start_time\n",
        "    train_times.append((name, train_duration))\n",
        "\n",
        "    _, test_acc = test(model, test_loader)\n",
        "    test_accs.append((name, test_acc))\n",
        "\n",
        "    histories.append(history)\n",
        "\n",
        "compare_models(histories, [n for n, _ in models], save_path='PyTorch4/Homework_4/results/custom_layers/metrics_resblocks.json')\n",
        "plot_metrics(histories, [n for n, _ in models], save_dir='PyTorch4/plots/custom_layers/')\n",
        "\n",
        "print(\"\\nСравнение числа параметров:\")\n",
        "for name, params in param_counts:\n",
        "    print(f\"{name}: {params}\")\n",
        "\n",
        "print(\"\\nВремя обучения (сек):\")\n",
        "for name, t_time in train_times:\n",
        "    print(f\"{name}: {t_time:.2f}\")\n",
        "\n",
        "print(\"\\nТочность на тестовом множестве:\")\n",
        "for name, acc in test_accs:\n",
        "    print(f\"{name}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWe_x_BpMLzM",
        "outputId": "e25fe174-7bfd-4ba8-fbcb-fc8953d903e1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
