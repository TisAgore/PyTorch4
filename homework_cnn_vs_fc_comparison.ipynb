{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcJRks4g9zrs"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual блок для ResNet.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1, dropout=0.0, use_bn=True):\n",
        "        super().__init__()\n",
        "        self.use_bn = use_bn\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout2d(dropout) if dropout > 0 else nn.Identity()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Выполняет прямое распространение через residual блок.\"\"\"\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return self.relu(out)\n",
        "\n",
        "class FCNet(nn.Module):\n",
        "    \"\"\"Полносвязная сеть с 4 слоями для MNIST.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Выполняет прямое распространение входных данных через сеть.\"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "class DeepFCNet(nn.Module):\n",
        "    \"\"\"Глубокая полносвязная сеть для CIFAR-10.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32*32*3, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Выполняет прямое распространение входных данных через сеть.\"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"Простая CNN с 3 сверточными слоями для MNIST.\"\"\"\n",
        "    def __init__(self, in_channels=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 16, 3, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class ResNetLike(nn.Module):\n",
        "    \"\"\"Простая CNN с Residual Block для MNIST.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.res1 = ResidualBlock(32, 64, downsample=True)\n",
        "        self.res2 = ResidualBlock(64, 128, downsample=True)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Выполняет прямое распространение входных данных через сеть с residual блоками.\"\"\"\n",
        "        x = nn.functional.relu(self.conv(x))\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNetCIFAR(nn.Module):\n",
        "    \"\"\"ResNet с 3 residual блоками для CIFAR-10.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 32, 3, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(32)\n",
        "        self.layer1 = ResidualBlock(32, 64, stride=2)\n",
        "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
        "        self.layer3 = ResidualBlock(128, 128, stride=2)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Выполняет прямое распространение входных данных через сеть с residual блоками.\"\"\"\n",
        "        x = nn.functional.relu(self.bn(self.conv(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNetCIFARRegularized(nn.Module):\n",
        "    \"\"\"ResNet с Dropout и BatchNorm для CIFAR-10.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 32, 3, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(32)\n",
        "        self.layer1 = ResidualBlock(32, 64, stride=2, dropout=0.3, use_bn=True)\n",
        "        self.layer2 = ResidualBlock(64, 128, stride=2, dropout=0.3, use_bn=True)\n",
        "        self.layer3 = ResidualBlock(128, 128, stride=2, dropout=0.3, use_bn=True)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Выполняет прямое распространение входных данных через сеть с регуляризацией.\"\"\"\n",
        "        x = nn.functional.relu(self.bn(self.conv(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rqyUHWaD_UXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "def get_data_loaders(dataset_name, batch_size=128):\n",
        "    \"\"\"Загружает и возвращает загрузчики данных для указанного датасета.\"\"\"\n",
        "    if dataset_name == 'MNIST':\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        train = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "        test = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "        class_names = [str(i) for i in range(10)]\n",
        "        return train_loader, test_loader, class_names\n",
        "    elif dataset_name == 'CIFAR10':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "        ])\n",
        "        train = datasets.CIFAR10('data', train=True, download=True, transform=transform_train)\n",
        "        test = datasets.CIFAR10('data', train=False, download=True, transform=transform_test)\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "        class_names = train.classes\n",
        "        return train_loader, test_loader, class_names\n",
        "    else:\n",
        "        raise ValueError(f\"Неизвестный датасет: {dataset_name}\")\n",
        "\n",
        "def plot_grad_flow(named_parameters, save_path):\n",
        "    \"\"\"Визуализирует средние значения градиентов по слоям.\"\"\"\n",
        "    ave_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if p.requires_grad and p.grad is not None and \"bias\" not in n:\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean().item())\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(ave_grads, alpha=0.7, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\", fontsize=8)\n",
        "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
        "    plt.xlabel(\"Слои\")\n",
        "    plt.ylabel(\"Средний градиент\")\n",
        "    plt.title(\"Градиентный поток\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "def train(model, train_loader, test_loader, epochs=20, log_prefix=\"\", grad_flow_plot=False, grad_flow_path=None):\n",
        "    device = next(model.parameters()).device\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = torch.nn.functional.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            if grad_flow_plot and grad_flow_path and epoch % 5 == 0:\n",
        "                plot_grad_flow(model.named_parameters(), grad_flow_path.replace('.png', f'_epoch{epoch}.png'))\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_acc = correct / total\n",
        "        test_loss, test_acc = test(model, test_loader)\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(test_acc)\n",
        "    return history\n",
        "\n",
        "def test(model, test_loader):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss += torch.nn.functional.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "    loss /= len(test_loader.dataset)\n",
        "    acc = correct / len(test_loader.dataset)\n",
        "    return loss, acc\n",
        "\n",
        "def get_feature_maps(model, img_tensor):\n",
        "    \"\"\"Возвращает feature maps первого conv-слоя для одного изображения.\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                return module(img_tensor).cpu().numpy()\n",
        "\n",
        "def measure_inference_time(model, data_loader, device):\n",
        "    \"\"\"Измеряет среднее время инференса на одном батче.\"\"\"\n",
        "    model.eval()\n",
        "    times = []\n",
        "    with torch.no_grad():\n",
        "        for data, _ in data_loader:\n",
        "            data = data.to(device)\n",
        "            start = time.time()\n",
        "            output = model(data)\n",
        "            torch.cuda.synchronize() if device.type == 'cuda' else None\n",
        "            end = time.time()\n",
        "            times.append(end - start)\n",
        "            break  # только один батч для оценки\n",
        "    return sum(times) / len(times) if times else 0\n",
        "\n",
        "def get_predictions(model, data_loader, device):\n",
        "    \"\"\"Возвращает истинные и предсказанные метки для всего датасета.\"\"\"\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1).cpu().numpy()\n",
        "            y_pred.extend(pred)\n",
        "            y_true.extend(target.numpy())\n",
        "    return np.array(y_true), np.array(y_pred)\n",
        "\n",
        "\n",
        "def compare_models(histories, labels, save_path):\n",
        "    \"\"\"Сохраняет сравнение историй обучения разных моделей в файл.\"\"\"\n",
        "    results = {}\n",
        "    for label, history in zip(labels, histories):\n",
        "        results[label] = {\n",
        "            'train_loss': history['train_loss'],\n",
        "            'test_loss': history['test_loss'],\n",
        "            'test_acc': history['test_acc'],\n",
        "        }\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Возвращает количество обучаемых параметров модели.\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def plot_metrics(histories, labels, save_dir):\n",
        "    \"\"\"Строит и сохраняет графики метрик обучения для нескольких моделей.\"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    metrics = ['train_loss', 'train_acc', 'test_loss', 'test_acc']\n",
        "    for metric in metrics:\n",
        "        plt.figure()\n",
        "        for history, label in zip(histories, labels):\n",
        "            plt.plot(history[metric], label=label)\n",
        "        plt.title(metric)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric)\n",
        "        plt.legend()\n",
        "        plt.savefig(os.path.join(save_dir, f\"{metric}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
        "    \"\"\"Строит и сохраняет confusion matrix.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "    disp.plot(ax=ax, cmap=plt.cm.Blues, colorbar=False)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "kPsQoGgD_2cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Сравнение на MNIST"
      ],
      "metadata": {
        "id": "DM2agjy0C9mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader, class_names = get_data_loaders('MNIST', batch_size=128)\n",
        "\n",
        "models = [\n",
        "    (\"DeepFCNet\", DeepFCNet().to(device)),\n",
        "    (\"ResNetCIFAR\", ResNetCIFAR().to(device)),\n",
        "    (\"ResNetCIFARRegularized\", ResNetCIFARRegularized().to(device))\n",
        "]\n",
        "\n",
        "histories = []\n",
        "train_times = []\n",
        "inference_times = []\n",
        "param_counts = []\n",
        "train_accs = []\n",
        "test_accs = []\n",
        "\n",
        "for name, model in models:\n",
        "    params = count_parameters(model)\n",
        "    param_counts.append((name, params))\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = train(model, train_loader, test_loader, epochs=10, log_prefix=name, grad_flow_plot=True)\n",
        "    train_duration = time.time() - start_time\n",
        "    train_times.append((name, train_duration))\n",
        "\n",
        "    train_acc = history['train_acc'][-1]\n",
        "    train_accs.append((name, train_acc))\n",
        "\n",
        "    test_loss, test_acc = test(model, test_loader)\n",
        "    test_accs.append((name, test_acc))\n",
        "\n",
        "    inf_time = measure_inference_time(model, test_loader, device)\n",
        "    inference_times.append((name, inf_time))\n",
        "\n",
        "    histories.append(history)\n",
        "\n",
        "    y_true, y_pred = get_predictions(model, test_loader, device)\n",
        "    plot_confusion_matrix(\n",
        "        y_true, y_pred, class_names,\n",
        "        save_path=f'PyTorch4/plots/cifar_comparison/conf_matrix_{name}.png'\n",
        "    )\n",
        "\n",
        "compare_models(histories, [n for n, _ in models], save_path='PyTorch4/results/cifar_comparison/metrics.json')\n",
        "plot_metrics(histories, [n for n, _ in models], save_dir='PyTorch4/plots/cifar_comparison/')\n",
        "\n",
        "print(\"\\nСравнение числа параметров:\")\n",
        "for name, params in param_counts:\n",
        "    print(f\"{name}: {params}\")\n",
        "\n",
        "print(\"\\nВремя обучения (с):\")\n",
        "for name, t in train_times:\n",
        "    print(f\"{name}: {t:.2f}\")\n",
        "\n",
        "print(\"\\nВремя инференса (с):\")\n",
        "for name, t in inference_times:\n",
        "    print(f\"{name}: {t:.4f}\")\n",
        "\n",
        "print(\"\\nТочность на обучающем:\")\n",
        "for name, acc in train_accs:\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "print(\"\\nТочность на тестовом:\")\n",
        "for name, acc in test_accs:\n",
        "    print(f\"{name}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "nEZB3xVrCa6f",
        "outputId": "0707672d-a214-4065-eda0-0c52a0dd2b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (128x784 and 3072x2048)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-28-170283619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_flow_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-27-4000849031.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, epochs, log_prefix, grad_flow_plot, grad_flow_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-26-4132158694.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"\"\"Выполняет прямое распространение входных данных через сеть.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSimpleCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x784 and 3072x2048)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Сравнение на СIFAR10"
      ],
      "metadata": {
        "id": "-mdQaOtcDvPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader, class_names = get_data_loaders('CIFAR10', batch_size=128)\n",
        "\n",
        "models = [\n",
        "    (\"DeepFCNet\", DeepFCNet().to(device)),\n",
        "    (\"ResNetCIFAR\", ResNetCIFAR().to(device)),\n",
        "    (\"ResNetCIFARRegularized\", ResNetCIFARRegularized().to(device))\n",
        "]\n",
        "\n",
        "histories = []\n",
        "train_times = []\n",
        "inference_times = []\n",
        "param_counts = []\n",
        "train_accs = []\n",
        "test_accs = []\n",
        "\n",
        "for name, model in models:\n",
        "    params = count_parameters(model)\n",
        "    param_counts.append((name, params))\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = train(model, train_loader, test_loader, epochs=10, log_prefix=name, grad_flow_plot=True)\n",
        "    train_duration = time.time() - start_time\n",
        "    train_times.append((name, train_duration))\n",
        "\n",
        "    train_acc = history['train_acc'][-1]\n",
        "    train_accs.append((name, train_acc))\n",
        "\n",
        "    test_loss, test_acc = test(model, test_loader)\n",
        "    test_accs.append((name, test_acc))\n",
        "\n",
        "    inf_time = measure_inference_time(model, test_loader, device)\n",
        "    inference_times.append((name, inf_time))\n",
        "\n",
        "    histories.append(history)\n",
        "\n",
        "    y_true, y_pred = get_predictions(model, test_loader, device)\n",
        "    plot_confusion_matrix(\n",
        "        y_true, y_pred, class_names,\n",
        "        save_path=f'PyTorch4/plots/cifar_comparison/conf_matrix_{name}.png'\n",
        "    )\n",
        "\n",
        "compare_models(histories, [n for n, _ in models], save_path='PyTorch4/results/cifar_comparison/metrics.json')\n",
        "plot_metrics(histories, [n for n, _ in models], save_dir='PyTorch4/plots/cifar_comparison/')\n",
        "\n",
        "print(\"\\nСравнение числа параметров:\")\n",
        "for name, params in param_counts:\n",
        "    print(f\"{name}: {params}\")\n",
        "\n",
        "print(\"\\nВремя обучения (с):\")\n",
        "for name, t in train_times:\n",
        "    print(f\"{name}: {t:.2f}\")\n",
        "\n",
        "print(\"\\nВремя инференса (с):\")\n",
        "for name, t in inference_times:\n",
        "    print(f\"{name}: {t:.4f}\")\n",
        "\n",
        "print(\"\\nТочность на обучающем:\")\n",
        "for name, acc in train_accs:\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "print(\"\\nТочность на тестовом:\")\n",
        "for name, acc in test_accs:\n",
        "    print(f\"{name}: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "b-45jCH0DzJs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}